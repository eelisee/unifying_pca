\section{Introduction: Questions Aimed to Answer}

Linear regression and PCA are two tools in multivariate analysis. Both reduce dimensionality, but they do so under conceptually different paradigms. Linear regression is a statistical approach utilizing s well-defined statistical model. PCA, however, relies on the same statistical model, but is traditionally implemented as a numerical procedure.

This paper addresses the following guiding questions:
\begin{itemize}
    \item Why do variable selection procedures in PCA and linear regression produce different outcomes, even though both are grounded in the same statistical model?
    \item Under which structural conditions do PCA-based and regression-based variable selections coincide?
    \item How can the differences be explained and formalized in an algebraic framework?
    \item What are the implications for practical selection methods such as forward selection, backward selection, and regularized regression?
\end{itemize}

Our contribution is threefold: 
(i) we present the theoretical groundwork of linear regression and PCA as statistical models; 
(ii) we interpret their sufficient statistics and explain the divergence of their estimators; 
(iii) we develop an algebraic operator framework that unifies linear regression and PCA and provides formal conditions for coincidence or divergence. 
Examples and comparisons with classical selection methods illustrate the theory. 
